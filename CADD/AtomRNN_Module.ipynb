{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ad64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_LOADED_ATOMRNN=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb9be6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Library 'General (RDKit)'\n",
      "PDB Tools Loaded\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%run /home/venkata/python/python_libraries/CADD/PDBReader.ipynb\n",
    "\n",
    "import sys,os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence,pad_sequence\n",
    "\n",
    "DEVICE=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5757b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the PDB file as string\n",
    "def readPDBAtomSeq(filename,skipHs=False):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    atypes=[ln[12:16].strip() for ln in lines if (ln[0:4]==\"ATOM\" or ln[0:6]==\"HETATM\") and ((skipHs and ln[12:16].strip()[0]!=\"H\") or (not skipHs))]\n",
    "    return atypes\n",
    "\n",
    "def readPDBFiles(files,N,S,skipHs=False):\n",
    "    rawdata=[]\n",
    "    K=0\n",
    "    L=0\n",
    "    print(\"Target:\",N)\n",
    "    #Skip first 'S', and read 'N' files\n",
    "    file_names = [fn for fn in files]\n",
    "    sorted(file_names)\n",
    "    for f in file_names:\n",
    "        if K<S:\n",
    "            K+=1\n",
    "            continue\n",
    "        if (L+1)%2500==0: print(L+1,f)\n",
    "        rawdata.append([OPENFLAG]+readPDBAtomSeq(folder+\"/\"+f,skipHs=skipHs))\n",
    "        L+=1\n",
    "        if L>=N: break\n",
    "    print(len(rawdata),\"files read\")\n",
    "    return rawdata\n",
    "def samplechar(poss):\n",
    "  posses=np.sum(poss)\n",
    "  if posses<1e-10: return np.random.choice(range(len(poss)))\n",
    "  else:\n",
    "    poss=np.nan_to_num(poss,0.)\n",
    "    poss/=sum(poss)\n",
    "  return np.random.choice(range(len(poss)),p=poss)\n",
    "def buildVocabulary(asets):\n",
    "    global MASK\n",
    "    vocab=set()\n",
    "    for aset in asets:\n",
    "        vocab=set.union(vocab,set(aset))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "688061b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some default parameters\n",
    "HIDE=\"\"\n",
    "MASK='\\0'\n",
    "SPLIT=\"~\"\n",
    "OPENFLAG=\"^\"\n",
    "MAXLEN=72\n",
    "BUFFER_SIZE=1000\n",
    "DTYPE_INT=torch.int64\n",
    "\n",
    "datafunc=readPDBAtomSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca51867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeAll(seqlist,keys=dict(),intlevel=torch.int32,strict=False):\n",
    "    maxint=max([keys[k] for k in keys.keys()],default=0)\n",
    "    nextint=maxint+1\n",
    "    ret=[]\n",
    "    for seq in seqlist:\n",
    "        intseq=[]\n",
    "        for el in seq:\n",
    "            if el in keys.keys(): intseq.append(keys[el])\n",
    "            else:\n",
    "                if strict: raise ValueError(\"Key not found: \"+str(el))\n",
    "                intseq.append(nextint)\n",
    "                keys[el]=nextint\n",
    "                nextint+=1\n",
    "        ret.append(torch.tensor(intseq,dtype=intlevel).to(DEVICE))\n",
    "    return ret,keys\n",
    "def rawdataToDataset(rawdata,keys=dict(),intlevel=DTYPE_INT,shuffle=True):\n",
    "    rawdata_encoded,encoded_keys=encodeAll(rawdata,keys,intlevel)\n",
    "    rawdata_encoded=pad_sequence(rawdata_encoded,batch_first=True)\n",
    "    if shuffle:\n",
    "        randord=torch.randperm(len(rawdata_encoded))\n",
    "        return rawdata_encoded[randord],encoded_keys\n",
    "    else:\n",
    "        return rawdata_encoded,encoded_keys\n",
    "    \n",
    "def forcePadding(padded_data,padding,crop=False):\n",
    "    if padding<=padded_data.shape[-1]: return padded_data if not crop else padded_data[:,:padding]\n",
    "    extzeros=torch.zeros((len(padded_data),padding-padded_data.shape[-1])).to(padded_data.device)\n",
    "    return torch.cat((padded_data,extzeros),dim=1)\n",
    "    \n",
    "\n",
    "def loadPDBsForTraining(filenames,N,S,shuffle=True,skipHs=False,keys=dict()): #Quick shortcut\n",
    "    rawdata=readPDBFiles(filenames,N,S,skipHs=skipHs)\n",
    "    return rawdataToDataset(rawdata,shuffle=shuffle,keys=keys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
