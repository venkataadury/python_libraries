{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03af30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_LOADED_TORCHNETS=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter, Linear, Sequential, BatchNorm1d, ReLU\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "from torch_geometric.nn import GCNConv, GATConv, EdgeConv\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "from torch.nn.utils.rnn import pack_padded_sequence,pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1b886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A generic PyTorch module wrapper for easy use\n",
    "class GenericModule(nn.Module):\n",
    "    def __init__(self,inshape,outshape):\n",
    "        super(GenericModule,self).__init__()\n",
    "        if type(inshape) == int: self.inshape=(inshape,)\n",
    "        else: self.inshape=inshape\n",
    "        if type(outshape) == int: self.outshape=(outshape,)\n",
    "        else: self.outshape=outshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943a6596",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(c_in, c_out)\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix,eps=1e-4):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            node_feats - Tensor with node features of shape [batch_size, num_nodes, c_in]\n",
    "            adj_matrix - Batch of adjacency matrices of the graph. If there is an edge from i to j, adj_matrix[b,i,j]=1 else 0.\n",
    "                         Supports directed edges by non-symmetric matrices. Assumes to already have added the identity connections. \n",
    "                         Shape: [batch_size, num_nodes, num_nodes]\n",
    "        \"\"\"\n",
    "        # Num neighbours = number of incoming edges\n",
    "        num_neighbours = adj_matrix.sum(dim=-1,keepdims=True)\n",
    "        node_feats = self.projection(node_feats.transpose(1,2)).transpose(1,2)\n",
    "        node_feats = torch.bmm(adj_matrix, node_feats)\n",
    "        node_feats = node_feats / (num_neighbours+eps)\n",
    "        return node_feats\n",
    "class MultiheadGCNLayer(nn.Module):\n",
    "    def __init__(self, c_in, c_out,filters):\n",
    "        super().__init__()\n",
    "        self.filters = nn.Parameter(torch.nn.init.xavier_uniform_(torch.zeros((filters,c_out,c_in),device=DEVICE)))\n",
    "        self.projection=nn.Linear(filters,1)\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix,eps=1e-4):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            node_feats - Tensor with node features of shape [batch_size, num_nodes, c_in]\n",
    "            adj_matrix - Batch of adjacency matrices of the graph. If there is an edge from i to j, adj_matrix[b,i,j]=1 else 0.\n",
    "                         Supports directed edges by non-symmetric matrices. Assumes to already have added the identity connections. \n",
    "                         Shape: [batch_size, num_nodes, num_nodes]\n",
    "        \"\"\"\n",
    "        # Num neighbours = number of incoming edges\n",
    "        num_neighbours = adj_matrix.sum(dim=-1,keepdims=True)\n",
    "        node_feats_ext=torch.matmul(self.filters,node_feats.transpose(-1,-2)[:,np.newaxis,:,:]).transpose(-1,-2).transpose(1,-1)\n",
    "        node_feats=self.projection(node_feats_ext).transpose(1,-1).squeeze()\n",
    "        #node_feats = self.projection(node_feats.transpose(1,2)).transpose(1,2)\n",
    "        node_feats = torch.bmm(adj_matrix, node_feats)\n",
    "        node_feats = node_feats / (num_neighbours+eps)\n",
    "        return node_feats\n",
    "class DeepIterativeGCN(nn.Module):\n",
    "    def __init__(self, c_in, c_outs,iters=2,acts=None): #c_outs is a list\n",
    "        super().__init__()\n",
    "        self.projections=[]\n",
    "        self.parameterlist=[]\n",
    "        if acts is None: acts=[None for _ in range(iters)]\n",
    "        if len(acts)<iters: acts+=[None]*(iters-len(acts))\n",
    "        self.acts=acts\n",
    "        self.iters=iters\n",
    "        for i in range(iters):\n",
    "            if len(c_outs)<=i: outv=c_outs[-1]\n",
    "            else: outv = c_outs[i]\n",
    "            self.projections.append(GCNLayer(c_in,outv))\n",
    "            for param in self.projections[-1].parameters(): self.parameterlist.append(param)\n",
    "            c_in=outv\n",
    "    \n",
    "    def parameters(self): return nn.ParameterList(self.parameterlist)\n",
    "    def to(self,dev):\n",
    "        for proj in self.projections: proj=proj.to(dev)\n",
    "        return self\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix,eps=1e-4):\n",
    "        ret=node_feats\n",
    "        for i in range(self.iters):\n",
    "            ret=self.projections[i](ret,adj_matrix,eps)\n",
    "            if self.acts[i] is not None: ret=self.acts[i](ret)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890c3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregations for GCN\n",
    "def meanAggregation(v):\n",
    "    return torch.mean(v,axis=1) #Axis 0 is batch-size\n",
    "def sigmoidMeanAggregation(v):\n",
    "    return F.sigmoid(torch.mean(v,axis=1))\n",
    "#A pure fully-connected layer wrapper.\n",
    "class PureNetwork(GenericModule):\n",
    "    # The pure decoder module that attempts to decode a molecule to a rep vector from the encoded vector\n",
    "    def __init__(self,encsize,layers=[1024,1024],acts=[F.relu,F.sigmoid]):\n",
    "        super(PureNetwork,self).__init__(encsize,layers[-1])\n",
    "        self.layers=[]\n",
    "        self.acts=[]\n",
    "        self.parameterlist=[]\n",
    "        cursize=int(np.prod(encsize))\n",
    "        for i,lnc in enumerate(layers):\n",
    "            self.layers.append(nn.Linear(cursize,lnc))\n",
    "            self.acts.append(acts[i])\n",
    "            for param in self.layers[-1].parameters(): self.parameterlist.append(param)\n",
    "            cursize=lnc\n",
    "    \n",
    "    def parameters(self): return nn.ParameterList(self.parameterlist)\n",
    "    def addLayer(self,lay,actF=None):\n",
    "        layers.append(lay)\n",
    "        acts.append(actf)\n",
    "        self.parameterlist.append(lay.parameters())\n",
    "    \n",
    "    def to(self,dev):\n",
    "        for lay in self.layers: lay=lay.to(DEVICE)\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self,x): return x; #Overridable\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.transform(x)\n",
    "        for i,lay in enumerate(self.layers):\n",
    "            x=lay(x)\n",
    "            if self.acts[i] is not None: x=self.acts[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcff192",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch Commons Loaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
